{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNetV3 in PyTorch.\n",
    "\n",
    "See the following papers for details:\n",
    "\n",
    "[Searching for MobileNetV3](https://arxiv.org/abs/1905.02244)\n",
    "\n",
    "[MobileNetV2: Inverted Residuals and Linear Bottlenecks](https://arxiv.org/abs/1801.04381)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python: 3.8.10 64-bit\n",
    "# os: ubuntu 20.04.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.nn import init\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch: 1.10.2\n",
      "cuda device: _CudaDeviceProperties(name='NVIDIA GeForce RTX 3080 Ti', major=8, minor=6, total_memory=12050MB, multi_processor_count=80)\n"
     ]
    }
   ],
   "source": [
    "print('pytorch:', torch.__version__)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    print('cuda device:', torch.cuda.get_device_properties('cuda:0'))\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('cuda device unavailable, using cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 15\n",
    "train_batch_size = 256\n",
    "test_batch_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class hswish(nn.Module):\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = x * F.relu6(x + 3, inplace=True) / 6\n",
    "        return out\n",
    "\n",
    "\n",
    "class hsigmoid(nn.Module):\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu6(x + 3, inplace=True) / 6\n",
    "        return out\n",
    "\n",
    "\n",
    "class SeModule(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_size, reduction=4):\n",
    "        super(SeModule, self).__init__()\n",
    "        self.se = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(in_size, in_size // reduction, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(in_size // reduction),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_size // reduction, in_size, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(in_size),\n",
    "            hsigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.se(x)\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    \n",
    "    '''expand + depthwise + pointwise'''\n",
    "\n",
    "    def __init__(self, kernel_size, in_size, expand_size, out_size, nolinear, semodule, stride):\n",
    "        super(Block, self).__init__()\n",
    "        self.stride = stride\n",
    "        self.se = semodule\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_size, expand_size, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(expand_size)\n",
    "        self.nolinear1 = nolinear\n",
    "        self.conv2 = nn.Conv2d(expand_size, expand_size, kernel_size=kernel_size, stride=stride, padding=kernel_size//2, groups=expand_size, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(expand_size)\n",
    "        self.nolinear2 = nolinear\n",
    "        self.conv3 = nn.Conv2d(expand_size, out_size, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_size)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        \n",
    "        if stride == 1 and in_size != out_size:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_size, out_size, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "                nn.BatchNorm2d(out_size),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.nolinear1(self.bn1(self.conv1(x)))\n",
    "        out = self.nolinear2(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        if self.se != None:\n",
    "            out = self.se(out)\n",
    "        out = out + self.shortcut(x) if self.stride == 1 else out\n",
    "        return out\n",
    "\n",
    "\n",
    "class MobileNetV3_Large(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes=256):\n",
    "        super(MobileNetV3_Large, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.hs1 = hswish()\n",
    "\n",
    "        self.bneck = nn.Sequential(\n",
    "            Block(3, 16, 16, 16, nn.ReLU(inplace=True), None, 1),\n",
    "            Block(3, 16, 64, 24, nn.ReLU(inplace=True), None, 2),\n",
    "            Block(3, 24, 72, 24, nn.ReLU(inplace=True), None, 1),\n",
    "            Block(5, 24, 72, 40, nn.ReLU(inplace=True), SeModule(40), 2),\n",
    "            Block(5, 40, 120, 40, nn.ReLU(inplace=True), SeModule(40), 1),\n",
    "            Block(5, 40, 120, 40, nn.ReLU(inplace=True), SeModule(40), 1),\n",
    "            Block(3, 40, 240, 80, hswish(), None, 2),\n",
    "            Block(3, 80, 200, 80, hswish(), None, 1),\n",
    "            Block(3, 80, 184, 80, hswish(), None, 1),\n",
    "            Block(3, 80, 184, 80, hswish(), None, 1),\n",
    "            Block(3, 80, 480, 112, hswish(), SeModule(112), 1),\n",
    "            Block(3, 112, 672, 112, hswish(), SeModule(112), 1),\n",
    "            Block(5, 112, 672, 160, hswish(), SeModule(160), 1),\n",
    "            Block(5, 160, 672, 160, hswish(), SeModule(160), 2),\n",
    "            Block(5, 160, 960, 160, hswish(), SeModule(160), 1),\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Conv2d(160, 960, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(960)\n",
    "        self.hs2 = hswish()\n",
    "        self.linear3 = nn.Linear(960, 1280)\n",
    "        self.bn3 = nn.BatchNorm1d(1280)\n",
    "        self.hs3 = hswish()\n",
    "        self.linear4 = nn.Linear(1280, num_classes)\n",
    "        self.init_params()\n",
    "\n",
    "    def init_params(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                init.constant_(m.weight, 1)\n",
    "                init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                init.normal_(m.weight, std=0.001)\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.hs1(self.bn1(self.conv1(x)))\n",
    "        out = self.bneck(out)\n",
    "        out = self.hs2(self.bn2(self.conv2(out)))\n",
    "        out = F.avg_pool2d(out, 7)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.hs3(self.bn3(self.linear3(out)))\n",
    "        out = self.linear4(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class MobileNetV3_Small(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes=256):\n",
    "        super(MobileNetV3_Small, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.hs1 = hswish()\n",
    "\n",
    "        self.bneck = nn.Sequential(\n",
    "            Block(3, 16, 16, 16, nn.ReLU(inplace=True), SeModule(16), 2),\n",
    "            Block(3, 16, 72, 24, nn.ReLU(inplace=True), None, 2),\n",
    "            Block(3, 24, 88, 24, nn.ReLU(inplace=True), None, 1),\n",
    "            Block(5, 24, 96, 40, hswish(), SeModule(40), 2),\n",
    "            Block(5, 40, 240, 40, hswish(), SeModule(40), 1),\n",
    "            Block(5, 40, 240, 40, hswish(), SeModule(40), 1),\n",
    "            Block(5, 40, 120, 48, hswish(), SeModule(48), 1),\n",
    "            Block(5, 48, 144, 48, hswish(), SeModule(48), 1),\n",
    "            Block(5, 48, 288, 96, hswish(), SeModule(96), 2),\n",
    "            Block(5, 96, 576, 96, hswish(), SeModule(96), 1),\n",
    "            Block(5, 96, 576, 96, hswish(), SeModule(96), 1),\n",
    "        )\n",
    "\n",
    "        self.conv2 = nn.Conv2d(96, 576, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(576)\n",
    "        self.hs2 = hswish()\n",
    "        self.linear3 = nn.Linear(576, 1280)\n",
    "        self.bn3 = nn.BatchNorm1d(1280)\n",
    "        self.hs3 = hswish()\n",
    "        self.linear4 = nn.Linear(1280, num_classes)\n",
    "        self.init_params()\n",
    "\n",
    "    def init_params(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                init.kaiming_normal_(m.weight, mode='fan_out')\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                init.constant_(m.weight, 1)\n",
    "                init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                init.normal_(m.weight, std=0.001)\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.hs1(self.bn1(self.conv1(x)))\n",
    "        out = self.bneck(out)\n",
    "        out = self.hs2(self.bn2(self.conv2(out)))\n",
    "        out = F.avg_pool2d(out, 7)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.hs3(self.bn3(self.linear3(out)))\n",
    "        out = self.linear4(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: ['0', '1', '2', '3', '4', 'B', 'C', 'E', 'M', 'P', 'R', 'S', 'T', '_']\n",
      "label index mapping: {'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, 'B': 5, 'C': 6, 'E': 7, 'M': 8, 'P': 9, 'R': 10, 'S': 11, 'T': 12, '_': 13}\n"
     ]
    }
   ],
   "source": [
    "datasetRoot = \"./dataset\"\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize([224, 224]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "dataset = ImageFolder(datasetRoot, transform=transform)\n",
    "classes = dataset.classes\n",
    "print('labels:', dataset.classes)\n",
    "print('label index mapping:', dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Training\n",
      "[1,    10] loss: 2.610\n",
      "[1,    20] loss: 2.512\n",
      "[1,    30] loss: 2.352\n",
      "[1,    40] loss: 2.123\n",
      "[1,    50] loss: 1.826\n",
      "[1,    60] loss: 1.474\n",
      "[1,    70] loss: 1.225\n",
      "[1,    80] loss: 1.151\n",
      "Accuracy of the network on the 2457 test images: 52 %\n",
      "[2,    10] loss: 0.989\n",
      "[2,    20] loss: 0.955\n",
      "[2,    30] loss: 0.894\n",
      "[2,    40] loss: 0.833\n",
      "[2,    50] loss: 0.776\n",
      "[2,    60] loss: 0.708\n",
      "[2,    70] loss: 0.707\n",
      "[2,    80] loss: 0.718\n",
      "Accuracy of the network on the 2457 test images: 59 %\n",
      "[3,    10] loss: 0.627\n",
      "[3,    20] loss: 0.588\n",
      "[3,    30] loss: 0.576\n",
      "[3,    40] loss: 0.541\n",
      "[3,    50] loss: 0.498\n",
      "[3,    60] loss: 0.499\n",
      "[3,    70] loss: 0.470\n",
      "[3,    80] loss: 0.445\n",
      "Accuracy of the network on the 2457 test images: 82 %\n",
      "[4,    10] loss: 0.425\n",
      "[4,    20] loss: 0.385\n",
      "[4,    30] loss: 0.347\n",
      "[4,    40] loss: 0.351\n",
      "[4,    50] loss: 0.330\n",
      "[4,    60] loss: 0.346\n",
      "[4,    70] loss: 0.326\n",
      "[4,    80] loss: 0.304\n",
      "Accuracy of the network on the 2457 test images: 89 %\n",
      "[5,    10] loss: 0.276\n",
      "[5,    20] loss: 0.251\n",
      "[5,    30] loss: 0.250\n",
      "[5,    40] loss: 0.261\n",
      "[5,    50] loss: 0.237\n",
      "[5,    60] loss: 0.247\n",
      "[5,    70] loss: 0.223\n",
      "[5,    80] loss: 0.216\n",
      "Accuracy of the network on the 2457 test images: 91 %\n",
      "[6,    10] loss: 0.185\n",
      "[6,    20] loss: 0.193\n",
      "[6,    30] loss: 0.177\n",
      "[6,    40] loss: 0.178\n",
      "[6,    50] loss: 0.171\n",
      "[6,    60] loss: 0.156\n",
      "[6,    70] loss: 0.152\n",
      "[6,    80] loss: 0.180\n",
      "Accuracy of the network on the 2457 test images: 91 %\n",
      "[7,    10] loss: 0.137\n",
      "[7,    20] loss: 0.142\n",
      "[7,    30] loss: 0.129\n",
      "[7,    40] loss: 0.113\n",
      "[7,    50] loss: 0.112\n",
      "[7,    60] loss: 0.139\n",
      "[7,    70] loss: 0.102\n",
      "[7,    80] loss: 0.128\n",
      "Accuracy of the network on the 2457 test images: 91 %\n",
      "[8,    10] loss: 0.098\n",
      "[8,    20] loss: 0.098\n",
      "[8,    30] loss: 0.096\n",
      "[8,    40] loss: 0.107\n",
      "[8,    50] loss: 0.099\n",
      "[8,    60] loss: 0.112\n",
      "[8,    70] loss: 0.087\n",
      "[8,    80] loss: 0.095\n",
      "Accuracy of the network on the 2457 test images: 95 %\n",
      "[9,    10] loss: 0.070\n",
      "[9,    20] loss: 0.078\n",
      "[9,    30] loss: 0.073\n",
      "[9,    40] loss: 0.066\n",
      "[9,    50] loss: 0.066\n",
      "[9,    60] loss: 0.077\n",
      "[9,    70] loss: 0.066\n",
      "[9,    80] loss: 0.064\n",
      "Accuracy of the network on the 2457 test images: 96 %\n",
      "[10,    10] loss: 0.056\n",
      "[10,    20] loss: 0.053\n",
      "[10,    30] loss: 0.060\n",
      "[10,    40] loss: 0.060\n",
      "[10,    50] loss: 0.049\n",
      "[10,    60] loss: 0.047\n",
      "[10,    70] loss: 0.056\n",
      "[10,    80] loss: 0.055\n",
      "Accuracy of the network on the 2457 test images: 96 %\n",
      "[11,    10] loss: 0.048\n",
      "[11,    20] loss: 0.046\n",
      "[11,    30] loss: 0.041\n",
      "[11,    40] loss: 0.049\n",
      "[11,    50] loss: 0.042\n",
      "[11,    60] loss: 0.053\n",
      "[11,    70] loss: 0.037\n",
      "[11,    80] loss: 0.041\n",
      "Accuracy of the network on the 2457 test images: 96 %\n",
      "[12,    10] loss: 0.035\n",
      "[12,    20] loss: 0.033\n",
      "[12,    30] loss: 0.035\n",
      "[12,    40] loss: 0.034\n",
      "[12,    50] loss: 0.030\n",
      "[12,    60] loss: 0.037\n",
      "[12,    70] loss: 0.041\n",
      "[12,    80] loss: 0.032\n",
      "Accuracy of the network on the 2457 test images: 96 %\n",
      "[13,    10] loss: 0.038\n",
      "[13,    20] loss: 0.024\n",
      "[13,    30] loss: 0.030\n",
      "[13,    40] loss: 0.043\n",
      "[13,    50] loss: 0.025\n",
      "[13,    60] loss: 0.031\n",
      "[13,    70] loss: 0.033\n",
      "[13,    80] loss: 0.032\n",
      "Accuracy of the network on the 2457 test images: 96 %\n",
      "[14,    10] loss: 0.026\n",
      "[14,    20] loss: 0.026\n",
      "[14,    30] loss: 0.030\n",
      "[14,    40] loss: 0.026\n",
      "[14,    50] loss: 0.025\n",
      "[14,    60] loss: 0.022\n",
      "[14,    70] loss: 0.028\n",
      "[14,    80] loss: 0.026\n",
      "Accuracy of the network on the 2457 test images: 96 %\n",
      "[15,    10] loss: 0.017\n",
      "[15,    20] loss: 0.017\n",
      "[15,    30] loss: 0.018\n",
      "[15,    40] loss: 0.023\n",
      "[15,    50] loss: 0.018\n",
      "[15,    60] loss: 0.014\n",
      "[15,    70] loss: 0.015\n",
      "[15,    80] loss: 0.022\n",
      "Accuracy of the network on the 2457 test images: 97 %\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "train_ids, test_ids = next(ShuffleSplit().split(dataset))\n",
    "\n",
    "train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
    "test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(dataset, batch_size=train_batch_size, num_workers=8, sampler=train_subsampler)\n",
    "testloader = torch.utils.data.DataLoader(dataset, batch_size=test_batch_size, num_workers=8, sampler=test_subsampler)\n",
    "\n",
    "net = MobileNetV3_Small(len(classes))\n",
    "net.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "print('Started Training')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        statistics = 10\n",
    "        if i % statistics == statistics - 1:\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / statistics))\n",
    "            running_loss = 0.0\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        net.eval()\n",
    "        for i, data in enumerate(testloader, 0):\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        net.train()\n",
    "        \n",
    "    print('Accuracy of the network on the %d test images: %d %%' % (total, 100 * correct / total))\n",
    "    \n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './mobilenet.pth'\n",
    "torch.save(net, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV3_Small(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (hs1): hswish()\n",
       "  (bneck): Sequential(\n",
       "    (0): Block(\n",
       "      (se): SeModule(\n",
       "        (se): Sequential(\n",
       "          (0): AdaptiveAvgPool2d(output_size=1)\n",
       "          (1): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): hsigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv1): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=16, bias=False)\n",
       "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (1): Block(\n",
       "      (conv1): Conv2d(16, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(72, 72, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=72, bias=False)\n",
       "      (bn2): BatchNorm2d(72, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (2): Block(\n",
       "      (conv1): Conv2d(24, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear1): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(88, 88, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=88, bias=False)\n",
       "      (bn2): BatchNorm2d(88, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear2): ReLU(inplace=True)\n",
       "      (conv3): Conv2d(88, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (3): Block(\n",
       "      (se): SeModule(\n",
       "        (se): Sequential(\n",
       "          (0): AdaptiveAvgPool2d(output_size=1)\n",
       "          (1): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (5): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): hsigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv1): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear1): hswish()\n",
       "      (conv2): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)\n",
       "      (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear2): hswish()\n",
       "      (conv3): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (4): Block(\n",
       "      (se): SeModule(\n",
       "        (se): Sequential(\n",
       "          (0): AdaptiveAvgPool2d(output_size=1)\n",
       "          (1): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (5): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): hsigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv1): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear1): hswish()\n",
       "      (conv2): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "      (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear2): hswish()\n",
       "      (conv3): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (5): Block(\n",
       "      (se): SeModule(\n",
       "        (se): Sequential(\n",
       "          (0): AdaptiveAvgPool2d(output_size=1)\n",
       "          (1): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (5): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): hsigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv1): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear1): hswish()\n",
       "      (conv2): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "      (bn2): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear2): hswish()\n",
       "      (conv3): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (6): Block(\n",
       "      (se): SeModule(\n",
       "        (se): Sequential(\n",
       "          (0): AdaptiveAvgPool2d(output_size=1)\n",
       "          (1): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): Conv2d(12, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (5): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): hsigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv1): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear1): hswish()\n",
       "      (conv2): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "      (bn2): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear2): hswish()\n",
       "      (conv3): Conv2d(120, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential(\n",
       "        (0): Conv2d(40, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): Block(\n",
       "      (se): SeModule(\n",
       "        (se): Sequential(\n",
       "          (0): AdaptiveAvgPool2d(output_size=1)\n",
       "          (1): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): Conv2d(12, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (5): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): hsigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv1): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear1): hswish()\n",
       "      (conv2): Conv2d(144, 144, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=144, bias=False)\n",
       "      (bn2): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear2): hswish()\n",
       "      (conv3): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (8): Block(\n",
       "      (se): SeModule(\n",
       "        (se): Sequential(\n",
       "          (0): AdaptiveAvgPool2d(output_size=1)\n",
       "          (1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (5): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): hsigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv1): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear1): hswish()\n",
       "      (conv2): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)\n",
       "      (bn2): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear2): hswish()\n",
       "      (conv3): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (9): Block(\n",
       "      (se): SeModule(\n",
       "        (se): Sequential(\n",
       "          (0): AdaptiveAvgPool2d(output_size=1)\n",
       "          (1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (5): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): hsigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv1): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear1): hswish()\n",
       "      (conv2): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "      (bn2): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear2): hswish()\n",
       "      (conv3): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "    (10): Block(\n",
       "      (se): SeModule(\n",
       "        (se): Sequential(\n",
       "          (0): AdaptiveAvgPool2d(output_size=1)\n",
       "          (1): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (2): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (3): ReLU(inplace=True)\n",
       "          (4): Conv2d(24, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (5): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (6): hsigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv1): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear1): hswish()\n",
       "      (conv2): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)\n",
       "      (bn2): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (nolinear2): hswish()\n",
       "      (conv3): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (shortcut): Sequential()\n",
       "    )\n",
       "  )\n",
       "  (conv2): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn2): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (hs2): hswish()\n",
       "  (linear3): Linear(in_features=576, out_features=1280, bias=True)\n",
       "  (bn3): BatchNorm1d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (hs3): hswish()\n",
       "  (linear4): Linear(in_features=1280, out_features=14, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = './mobilenet.pth'\n",
    "net = torch.load(PATH, map_location=device)\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_size: torch.Size([8, 3, 224, 224])\n",
      "predicted: P ,  label_id:  tensor(9) ,  label: P\n",
      "input_size: torch.Size([8, 3, 224, 224])\n",
      "predicted: C ,  label_id:  tensor(6) ,  label: C\n",
      "input_size: torch.Size([8, 3, 224, 224])\n",
      "predicted: 4 ,  label_id:  tensor(4) ,  label: 4\n",
      "input_size: torch.Size([8, 3, 224, 224])\n",
      "predicted: M ,  label_id:  tensor(8) ,  label: M\n",
      "input_size: torch.Size([8, 3, 224, 224])\n",
      "predicted: C ,  label_id:  tensor(6) ,  label: C\n",
      "input_size: torch.Size([8, 3, 224, 224])\n",
      "predicted: 2 ,  label_id:  tensor(2) ,  label: 2\n",
      "input_size: torch.Size([8, 3, 224, 224])\n",
      "predicted: S ,  label_id:  tensor(11) ,  label: S\n",
      "input_size: torch.Size([8, 3, 224, 224])\n",
      "predicted: T ,  label_id:  tensor(12) ,  label: T\n",
      "input_size: torch.Size([8, 3, 224, 224])\n",
      "predicted: C ,  label_id:  tensor(6) ,  label: C\n",
      "input_size: torch.Size([8, 3, 224, 224])\n",
      "predicted: _ ,  label_id:  tensor(13) ,  label: _\n",
      "input_size: torch.Size([8, 3, 224, 224])\n",
      "predicted: 3 ,  label_id:  tensor(3) ,  label: 3\n",
      "input_size: torch.Size([8, 3, 224, 224])\n",
      "predicted: 2 ,  label_id:  tensor(2) ,  label: 2\n",
      "input_size: torch.Size([8, 3, 224, 224])\n",
      "predicted: C ,  label_id:  tensor(6) ,  label: C\n",
      "input_size: torch.Size([8, 3, 224, 224])\n",
      "predicted: C ,  label_id:  tensor(6) ,  label: C\n",
      "input_size: torch.Size([8, 3, 224, 224])\n",
      "predicted: B ,  label_id:  tensor(5) ,  label: B\n",
      "input_size: torch.Size([8, 3, 224, 224])\n",
      "predicted: C ,  label_id:  tensor(6) ,  label: C\n",
      "input_size: torch.Size([8, 3, 224, 224])\n",
      "predicted: _ ,  label_id:  tensor(13) ,  label: _\n",
      "input_size: torch.Size([8, 3, 224, 224])\n",
      "predicted: 3 ,  label_id:  tensor(3) ,  label: 3\n",
      "input_size: torch.Size([8, 3, 224, 224])\n",
      "predicted: _ ,  label_id:  tensor(13) ,  label: _\n",
      "input_size: torch.Size([8, 3, 224, 224])\n",
      "predicted: 4 ,  label_id:  tensor(4) ,  label: 4\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "\n",
    "for i in range(20):\n",
    "    \n",
    "    images, labels = dataiter.next()\n",
    "    print('input_size:', images.size())\n",
    "    outputs = net(images.to(device))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    \n",
    "    # show image\n",
    "    # images[0] = images[0] / 2 + 0.5     # unnormalize\n",
    "    # npimg = images[0].numpy()\n",
    "    # plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    # plt.show()\n",
    "    \n",
    "    print('predicted:', classes[predicted[0]], ',  label_id: ', labels[0], ',  label:', classes[labels[0]])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f993f44dd029ec6fef3e998aefd949414881400fb305464eb405b83997ce6a96"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('main': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
